<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Tutorial &#8212; emloop 0.1.1 documentation</title>
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/highlight.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Advanced" href="advanced/index.html" />
    <link rel="prev" title="Getting Started" href="getting_started.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head><body>

  <div id="navbar" class="navbar navbar-inverse navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          emloop</a>
        <span class="navbar-text navbar-version pull-left"><b>0.1</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="getting_started.html">Getting Started</a></li>
                <li><a href="#">Tutorial</a></li>
                <li><a href="advanced/index.html">Advanced</a></li>
                <li><a href="cli.html">CLI Reference</a></li>
                <li><a href="emloop/index.html">API Reference</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Pages <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
            
            
            
            
            
          </ul>
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="col-md-3">
        <div id="sidebar" class="bs-sidenav" role="complementary">
<div class="side_nav">
    <a href="getting_started.html" title="Previous Chapter: Getting Started"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Getting Started</span>
    </a>
    </div>
<div class="side_nav">
    <a href="advanced/index.html" title="Next Chapter: Advanced"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Advanced &raquo;</span>
    </a>
    </div><ul>
<li><a class="reference internal" href="#">Tutorial</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#task">Task</a></li>
<li><a class="reference internal" href="#dataset">Dataset</a></li>
<li><a class="reference internal" href="#model">Model</a></li>
<li><a class="reference internal" href="#configuration">Configuration</a><ul>
<li><a class="reference internal" href="#id2">Dataset</a></li>
<li><a class="reference internal" href="#id3">Model</a></li>
<li><a class="reference internal" href="#main-loop">Main Loop</a></li>
<li><a class="reference internal" href="#hooks">Hooks</a></li>
<li><a class="reference internal" href="#using-emloop">Using emloop</a></li>
</ul>
</li>
</ul>
</li>
</ul>

<form action="search.html" method="get" class="searchbox">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form><div class="side_nav">
	<h4>Related projects</h4>
</div>
<ul class="nav nav-list">
	<li><a href="https://emloop.org">emloop</a></li>
	<li><a href="https://tensorflow.emloop.org">emloop-tensorflow</a></li>
	<li><a href="https://hipipe.org">hipipe (c++)</a></li>
</ul>
        </div>
      </div>
    <div class="col-md-9 content">
      
  <div class="section" id="tutorial">
<h1>Tutorial<a class="headerlink" href="#tutorial" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, we are using an example task to demonstrate&nbsp;emloop’s&nbsp;basic
principles.</p>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p><strong>emloop</strong> is a lightweight framework for machine learning which focuses on:</p>
<ul class="simple">
<li>modularization and re-usability of ML components (datasets, models etc.)</li>
<li>rapid experimenting with different configurations</li>
<li>providing convenient instruments to manage and run your experiments</li>
</ul>
<p><strong>emloop</strong> does not implement any building blocks, NN layers etc. Instead, you can use
your favorite machine learning framework, such as <a class="reference external" href="https://www.tensorflow.org/">TensorFlow</a>,
<a class="reference external" href="https://cntk.ai/">CNTK</a>, or <a class="reference external" href="https://caffe2.ai/">Caffe2</a>. In other words,
<strong>emloop</strong> is back-end agnostic.
Therefore, you don’t have to learn a new framework, if you already know one.
In addition, you can easily convert the models you already have by making only
minimal changes.</p>
<p><strong>emloop</strong> allows (and encourages) you to build modular projects, where the
dataset, the model, and the configuration are separated and reusable. In the following sections,
we will describe how those reusable modules should look like on a simple
example.</p>
</div>
<div class="section" id="task">
<h2>Task<a class="headerlink" href="#task" title="Permalink to this headline">¶</a></h2>
<p>The tutorial will be demonstrated on a simple task called <em>majority</em>.
Given a vector of N bits, which bit is in majority?</p>
<p>Example of few 5-bit vectors:</p>
<table border="1" class="docutils">
<colgroup>
<col width="19%" />
<col width="23%" />
<col width="22%" />
<col width="36%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>input vector</td>
<td>number of zeros</td>
<td>number of ones</td>
<td>bit in majority (target)</td>
</tr>
<tr class="row-even"><td>00101</td>
<td>3</td>
<td>2</td>
<td>0</td>
</tr>
<tr class="row-odd"><td>00000</td>
<td>5</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="row-even"><td>10101</td>
<td>2</td>
<td>3</td>
<td>1</td>
</tr>
<tr class="row-odd"><td>11101</td>
<td>1</td>
<td>4</td>
<td>1</td>
</tr>
</tbody>
</table>
<div class="admonition tip">
<p class="first admonition-title">Tip</p>
<p class="last">Full example may be found in our
<a class="reference external" href="https://github.com/iterait/emloop-examples/tree/master/majority">emloop examples repository &#64;GitHub</a>.</p>
</div>
</div>
<div class="section" id="dataset">
<h2>Dataset<a class="headerlink" href="#dataset" title="Permalink to this headline">¶</a></h2>
<p>The very first step in any machine learning task is to load and process the data.
Every <strong>emloop</strong> dataset is expected to implement the interface defined by <a class="reference internal" href="emloop/emloop.datasets.html#emloop.datasets.AbstractDataset" title="emloop.datasets.AbstractDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">emloop.datasets.AbstractDataset</span></code></a>.
At the moment, the interfaces defines only the constructor API which accepts a string-encoded YAML.
For regular projects, we recommend extending <a class="reference internal" href="emloop/emloop.datasets.html#emloop.datasets.BaseDataset" title="emloop.datasets.BaseDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">emloop.datasets.BaseDataset</span></code></a> which decodes the YAML
configuration string for you.</p>
<p>The dataset is meant to wrap all data-related operations.
It is responsible for correct data loading, verification and other useful operations.
The main purpose of the dataset is providing various data streams that will be consequently used for training,
validation and prediction in the production environment.</p>
<p>A typical <strong>emloop</strong> dataset will implement the following:</p>
<ol class="arabic simple">
<li><strong>Training stream:</strong> an iteration of training data batches (<code class="docutils literal notranslate"><span class="pre">train_stream</span></code> method)</li>
<li><strong>Eval streams:</strong> iterations of additional streams not used for training.
To provide a stream named &lt;name&gt;, method <code class="docutils literal notranslate"><span class="pre">&lt;name&gt;_stream</span></code> needs to return its iterator.
In our example, we will use <em>test</em> stream provided by <code class="docutils literal notranslate"><span class="pre">test_stream</span></code> method.</li>
<li><strong>The constructor:</strong> accepts a YAML configuration in the form of a string
(more on this later). We avoid the need to implement a constructor by
extending <a class="reference internal" href="emloop/emloop.datasets.html#emloop.datasets.BaseDataset" title="emloop.datasets.BaseDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">emloop.datasets.BaseDataset</span></code></a>.</li>
<li><strong>Additional methods:</strong> such as <code class="docutils literal notranslate"><span class="pre">fetch</span></code>, <code class="docutils literal notranslate"><span class="pre">split</span></code>, or anything else you may need.
<strong>emloop</strong> is able to call arbitrary dataset methods by invoking <code class="docutils literal notranslate"><span class="pre">emloop</span> <span class="pre">dataset</span> <span class="pre">&lt;method-name&gt;</span></code> command.</li>
</ol>
<p>To generate the <em>majority</em> data and provide the data streams we will implement a <code class="docutils literal notranslate"><span class="pre">MajorityDataset</span></code>:</p>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-text">majority_dataset.py</span><a class="headerlink" href="#id4" title="Permalink to this code">¶</a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">emloop</span> <span class="kn">as</span> <span class="nn">el</span>
<span class="kn">import</span> <span class="nn">numpy.random</span> <span class="kn">as</span> <span class="nn">npr</span>


<span class="k">class</span> <span class="nc">MajorityDataset</span><span class="p">(</span><span class="n">el</span><span class="o">.</span><span class="n">BaseDataset</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">_configure_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_examples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">npr</span><span class="o">.</span><span class="n">random_integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_examples</span> <span class="o">*</span> <span class="n">dim</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_examples</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">int</span><span class="p">(</span><span class="n">dim</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_train_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_y</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="o">.</span><span class="mi">8</span> <span class="o">*</span> <span class="n">n_examples</span><span class="p">)],</span> <span class="n">y</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="o">.</span><span class="mi">8</span> <span class="o">*</span> <span class="n">n_examples</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_test_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_y</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="o">.</span><span class="mi">8</span> <span class="o">*</span> <span class="n">n_examples</span><span class="p">):],</span> <span class="n">y</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="o">.</span><span class="mi">8</span> <span class="o">*</span> <span class="n">n_examples</span><span class="p">):]</span>

    <span class="k">def</span> <span class="nf">train_stream</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">el</span><span class="o">.</span><span class="n">Stream</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span><span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_x</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">],</span>
                   <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_y</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]}</span>

    <span class="k">def</span> <span class="nf">test_stream</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">el</span><span class="o">.</span><span class="n">Stream</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_test_x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span><span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_x</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">],</span>
                   <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_y</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]}</span>
</pre></div>
</div>
</div>
<p>Let us describe the functionality of our <code class="docutils literal notranslate"><span class="pre">MajorityDataset</span></code> step by step.
We shall begin with the <code class="docutils literal notranslate"><span class="pre">_configure_dataset</span></code> method.
This method is called automatically by the dataset constructor, which provides it with the
parameters from the configuration file (configuration will be explained later).
In our case, we need <code class="docutils literal notranslate"><span class="pre">n_examples</span></code> (the number of examples in total), <code class="docutils literal notranslate"><span class="pre">dim</span></code> (the dimension of the
generated data) and <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> (how big our batches will be).</p>
<p>The method randomly generates a dataset of <code class="docutils literal notranslate"><span class="pre">n_examples</span></code> vectors of ones and zeros (variable <code class="docutils literal notranslate"><span class="pre">x</span></code>).
For each of those vectors, it calculates the correct answer (variable <code class="docutils literal notranslate"><span class="pre">y</span></code>).
Finally, it splits the dataset into training and testing data in the ratio of 8:2.</p>
<p>To sum up, once the dataset is constructed, it features four attributes (<code class="docutils literal notranslate"><span class="pre">_train_x</span></code>,
<code class="docutils literal notranslate"><span class="pre">_train_y</span></code>, <code class="docutils literal notranslate"><span class="pre">_test_x</span></code> and <code class="docutils literal notranslate"><span class="pre">_test_y</span></code>) that represent the loaded data.
Note that you have the option to rename them as desired.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">In real-world cases, we usually don’t want to generate our data randomly.
Instead, we can simply load them from a file (e.g. <code class="docutils literal notranslate"><span class="pre">.csv</span></code>) or from a database.</p>
</div>
<p>The train_stream&nbsp;function iterates over the training data.
This function returns an iterator over batches.
Each <em>batch</em> is a dictionary with keys <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code>, where the value of <code class="docutils literal notranslate"><span class="pre">x</span></code> is a list of
training vectors and the value of <code class="docutils literal notranslate"><span class="pre">y</span></code> is the list of the correct answers.
The lists have the length of <code class="docutils literal notranslate"><span class="pre">batch_size</span></code>.</p>
<p>A batch (with <code class="docutils literal notranslate"><span class="pre">batch_size=4</span></code>) representing the example above looks like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
    <span class="p">],</span>
    <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span>
    <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Similarly, there is a <code class="docutils literal notranslate"><span class="pre">test_stream</span></code> function that iterates over the testing data.</p>
<p>A single iteration over the whole dataset is called an <em>epoch</em>.
We train our machine learning models by iterating through the training stream
for one or more epochs.
The test stream is used only to estimate the performance of the model.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">In this example, the training and testing streams are generated randomly and thus,
they may slightly overlap and bias the performace estimation.</p>
</div>
<p>A detailed description of <strong>emloop</strong> datasets might be found in the
<a class="reference internal" href="advanced/dataset.html"><span class="doc">advanced section</span></a>.</p>
</div>
<div class="section" id="model">
<h2>Model<a class="headerlink" href="#model" title="Permalink to this headline">¶</a></h2>
<p>With the dataset ready, we now must define the model that is to be trained.
A simple <a class="reference external" href="https://www.tensorflow.org/">TensorFlow</a> graph can solve our task.
We will use the official <a class="reference external" href="https://github.com/iterait/emloop-tensorflow">emloop-tensorflow</a> package that provides
convenient TensorFlow integration with <strong>emloop</strong>. Please install this package before you proceed
with this tutorial.</p>
<p>In <a class="reference external" href="https://tensorflow.emloop.org/emloop_tensorflow/emloop_tensorflow.html#module-emloop_tensorflow" title="(in emloop-tensorflow v0.1)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">emloop_tensorflow</span></code></a>, every model is a python class that is expected to
extend the <a class="reference external" href="https://tensorflow.emloop.org/emloop_tensorflow/emloop_tensorflow.html#emloop_tensorflow.BaseModel" title="(in emloop-tensorflow v0.1)"><code class="xref py py-class docutils literal notranslate"><span class="pre">emloop_tensorflow.BaseModel</span></code></a>.</p>
<p>Let us define a class called <code class="docutils literal notranslate"><span class="pre">MajorityNet</span></code>.</p>
<div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-text">majority_net.py</span><a class="headerlink" href="#id5" title="Permalink to this code">¶</a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">logging</span>

<span class="kn">import</span> <span class="nn">emloop_tensorflow</span> <span class="kn">as</span> <span class="nn">eltf</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow.contrib.keras</span> <span class="kn">as</span> <span class="nn">K</span>


<span class="k">class</span> <span class="nc">MajorityNet</span><span class="p">(</span><span class="n">eltf</span><span class="o">.</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Simple 2-layered MLP for majority task.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">&#39;Constructing placeholders matching the model.inputs&#39;</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="o">.</span><span class="n">dim</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">&#39;Constructing MLP model&#39;</span><span class="p">)</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hidden</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">net</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">&#39;Constructing loss and outputs matching the model.outputs&#39;</span><span class="p">)</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;predictions&#39;</span><span class="p">)</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">bool</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The only method that is necessary to implement is <a class="reference external" href="https://tensorflow.emloop.org/emloop_tensorflow/emloop_tensorflow.html#emloop_tensorflow.BaseModel._create_model" title="(in emloop-tensorflow v0.1)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">emloop_tensorflow.BaseModel._create_model()</span></code></a>.
In our case, the <code class="docutils literal notranslate"><span class="pre">_create_model</span></code> method creates a simple MLP.
If you know the fundamentals of TensorFlow, it should be easy to understand what is going on.</p>
<p>To be precise, the model registered the following computational graph nodes:</p>
<ol class="arabic simple">
<li>Placeholders <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> corresponding to a single batch from the stream (only the batch sources <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> will be mapped to these placeholders).</li>
<li>Variable <code class="docutils literal notranslate"><span class="pre">loss</span></code> denoting the mean square error of the model.</li>
<li>Variable <code class="docutils literal notranslate"><span class="pre">predictions</span></code> denoting the output of the network, i.e., the bit
predicted to be in majority.</li>
<li>Variable <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> denoting the fraction of correct predictions in the current batch.</li>
</ol>
<div class="admonition caution">
<p class="first admonition-title">Caution</p>
<p class="last">For each of input/output variables listed in the configuration, there has to
exist a computational graph node with the corresponding name.
<strong>emloop-tensorflow</strong> is not able to find the nodes if they are not properly
named.</p>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">_create_model</span></code> method can accept arbitrary arguments - in our case, we allow to configure the number of hidden units.
We will describe the configuration file from which the parameters are taken in the next section.</p>
<p>You can find detailed descriptions of&nbsp;emloop&nbsp;models in the&nbsp;<a class="reference internal" href="advanced/model.html"><span class="doc">advanced section</span></a>.</p>
</div>
<div class="section" id="configuration">
<h2>Configuration<a class="headerlink" href="#configuration" title="Permalink to this headline">¶</a></h2>
<p>The configuration of the training is the final, most important part of our tutorial.
The configuration or <em>config</em> defines which dataset will be used as the data source
and which model will be employed for training.</p>
<p>The configuration file is in the form of a YAML document.
Feel free to use JSON instead, however, YAML makes a lot of things easier.</p>
<p>The YAML document consists of four fundamental sections.
A detailed description of emloop configuration can be found in the <a class="reference internal" href="advanced/config.html"><span class="doc">advanced section</span></a>.</p>
<ol class="arabic simple">
<li>dataset</li>
<li>model</li>
<li>main_loop</li>
<li>hooks</li>
</ol>
<p>Let us describe the sections one by one.</p>
<div class="section" id="id2">
<h3>Dataset<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>In our case, we only need to tell <strong>emloop</strong> which dataset to use.
This is done by specifying the <code class="docutils literal notranslate"><span class="pre">class</span></code> of the dataset.
In addition, we will specify the parameters of the dataset (those
are passed to the <code class="docutils literal notranslate"><span class="pre">_configure_dataset</span></code> method of the dataset).</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">dataset</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">class</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">majority.MajorityDataset</span>
  <span class="l l-Scalar l-Scalar-Plain">n_examples</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">500</span>
  <span class="l l-Scalar l-Scalar-Plain">dim</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">11</span>
  <span class="l l-Scalar l-Scalar-Plain">batch_size</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
</pre></div>
</div>
<p>We can pass arbitrary constants to the dataset that will be hidden in the
<code class="docutils literal notranslate"><span class="pre">**kwargs</span></code> parameter of the <code class="docutils literal notranslate"><span class="pre">_configure_dataset</span></code> method of the dataset.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The whole <code class="docutils literal notranslate"><span class="pre">dataset</span></code> section will be passed as a string-encoded YAML to the dataset constructor.
In the case of using <a class="reference internal" href="emloop/emloop.datasets.html#emloop.datasets.BaseDataset" title="emloop.datasets.BaseDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">emloop.datasets.BaseDataset</span></code></a>, the YAML is automatically decoded and the individual
variables are passed to the <code class="docutils literal notranslate"><span class="pre">_configure_dataset</span></code> method.</p>
</div>
</div>
<div class="section" id="id3">
<h3>Model<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>Similarly to the dataset, the model is defined in the <code class="docutils literal notranslate"><span class="pre">model</span></code> section.
In our case, we want to specify the <code class="docutils literal notranslate"><span class="pre">class</span></code> of the model along with <code class="docutils literal notranslate"><span class="pre">optimizer</span></code> and
<code class="docutils literal notranslate"><span class="pre">hidden</span></code> as required by the <code class="docutils literal notranslate"><span class="pre">_create_model</span></code> method of the model.
In addition, we will specify the <code class="docutils literal notranslate"><span class="pre">name</span></code> of the network which will be used for naming the
logging directory.</p>
<p>In addition, we have to specify which TensorFlow variable names are the network inputs
and which variable names are on the output.
This can be done by listing their names in the <code class="docutils literal notranslate"><span class="pre">inputs</span></code> and <code class="docutils literal notranslate"><span class="pre">outputs</span></code> config items.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">model</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">MajorityExample</span>
  <span class="l l-Scalar l-Scalar-Plain">class</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">majority.MajorityNet</span>

  <span class="l l-Scalar l-Scalar-Plain">optimizer</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">class</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">AdamOptimizer</span>
    <span class="l l-Scalar l-Scalar-Plain">learning_rate</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">0.001</span>

  <span class="l l-Scalar l-Scalar-Plain">hidden</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">100</span>

  <span class="l l-Scalar l-Scalar-Plain">inputs</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="nv">x</span><span class="p p-Indicator">,</span> <span class="nv">y</span><span class="p p-Indicator">]</span>
  <span class="l l-Scalar l-Scalar-Plain">outputs</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="nv">accuracy</span><span class="p p-Indicator">,</span> <span class="nv">predictions</span><span class="p p-Indicator">,</span> <span class="nv">loss</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
</div>
<div class="section" id="main-loop">
<h3>Main Loop<a class="headerlink" href="#main-loop" title="Permalink to this headline">¶</a></h3>
<p>As the model training is executed in epochs, it is naturally implemented as a loop.
This loop (<a class="reference internal" href="emloop/emloop.html#emloop.MainLoop" title="emloop.MainLoop"><code class="xref py py-class docutils literal notranslate"><span class="pre">emloop.MainLoop</span></code></a>) can be extended, for example by adding more
streams to the <code class="docutils literal notranslate"><span class="pre">train</span></code> stream.
In our case, we also want to evaluate the <code class="docutils literal notranslate"><span class="pre">test</span></code> stream, so we will add it to the
<code class="docutils literal notranslate"><span class="pre">main_loop.extra_streams</span></code> section of the config. <strong>emloop</strong> will then invoke
the <code class="docutils literal notranslate"><span class="pre">&lt;name&gt;_stream</span></code> method of the dataset to create the stream. In our case,
the <code class="docutils literal notranslate"><span class="pre">test_stream</span></code> method will be invoked.</p>
<div class="literal-block-wrapper docutils container" id="id6">
<div class="code-block-caption"><span class="caption-text">evaluate additional streams</span><a class="headerlink" href="#id6" title="Permalink to this code">¶</a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">main_loop</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">extra_streams</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="nv">test</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="hooks">
<h3>Hooks<a class="headerlink" href="#hooks" title="Permalink to this headline">¶</a></h3>
<p>Hooks can observe, modify and control the training process. In particular, hook actions are triggered after certain events,
such as after a batch or an epoch is completed (more info in <a class="reference internal" href="advanced/hook.html"><span class="doc">advanced section</span></a>).</p>
<p>The hooks to be used are specified in <strong>emloop</strong> configuration similar to the following one:</p>
<div class="literal-block-wrapper docutils container" id="id7">
<div class="code-block-caption"><span class="caption-text">hook configuration section</span><a class="headerlink" href="#id7" title="Permalink to this code">¶</a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">hooks</span><span class="p p-Indicator">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">ComputeStats</span><span class="p p-Indicator">:</span>
      <span class="l l-Scalar l-Scalar-Plain">variables</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="nv">loss</span><span class="p p-Indicator">,</span> <span class="nv">accuracy</span><span class="p p-Indicator">]</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">LogVariables</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">StopAfter</span><span class="p p-Indicator">:</span>
      <span class="l l-Scalar l-Scalar-Plain">epochs</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
</pre></div>
</div>
</div>
<p>This section can be read quite naturally. <strong>emloop</strong> will now compute <code class="docutils literal notranslate"><span class="pre">loss</span></code> and <code class="docutils literal notranslate"><span class="pre">accuracy</span></code>
means for each epoch and log the respective values. The training will be stopped after 10 epochs.</p>
<div class="admonition tip">
<p class="first admonition-title">Tip</p>
<p class="last">See <a class="reference external" href="emloop/emloop.hooks.html">API reference</a> for full list of <strong>emloop</strong> hooks.</p>
</div>
</div>
<div class="section" id="using-emloop">
<h3>Using emloop<a class="headerlink" href="#using-emloop" title="Permalink to this headline">¶</a></h3>
<p>Once the classes and config are implemented, the training can begin.
Let’s try it with</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>emloop train majority/config.yaml
</pre></div>
</div>
<p>The command produces a lot of output.
The first section describes the creation of the components.
The second part presents the output of the hooks.
Finally, our logging hook is the one that produces the information after each epoch.
Now we can easily watch the progress of the training.</p>
<p>After the training is finished, note that there is a new directory <code class="docutils literal notranslate"><span class="pre">log/MajorityExample_*</span></code>.
This is the logging directory where everything <strong>emloop</strong> produces is stored, including
saved models, the configuration file and various other artifacts.</p>
<p>Let’s register one more hook which saves the best model according to the test stream:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">SaveBest</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">stream</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">test</span>
</pre></div>
</div>
<p>When we run the training again, we see that the newly created output directory contains
the saved model as well.</p>
<p>Let’s resume the training from this model.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>emloop resume log/MajorityExample_&lt;some-suffix&gt;
</pre></div>
</div>
<p>It’s simple as that.</p>
<p>In case the model is good enough to be used in the production, it is extremely
easy to use emloop for this purpose.
See the configuration <a class="reference internal" href="advanced/config.html"><span class="doc">advanced section</span></a> for more details.
Then, you can just run the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>emloop <span class="nb">eval</span> predict log/MajorityExample_&lt;some-suffix&gt;
</pre></div>
</div>
</div>
</div>
</div>


    </div>
      
  </div>
</div>

<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2018, Iterait a.s..<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.9.<br/>
    </p>
  </div>
</footer>

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-108491604-2"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-108491604-2');
</script>



  </body>
</html>